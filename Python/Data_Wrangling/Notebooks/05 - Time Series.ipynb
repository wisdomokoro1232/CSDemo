{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series\n",
    "- Basics\n",
    "- slicing into timezones\n",
    "- ranges and frequencies\n",
    "- resampling\n",
    "- shift and tshift\n",
    "- interpolation\n",
    "- moving windows - rolling and expanding\n",
    "- aggregating data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning) \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# format for floats\n",
    "pd.options.display.float_format = '{:,.2f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Basics\n",
    "\n",
    "- Always pay attention to how pandas builds indexes that are timeseries\n",
    "- Especially true when loading in Data from multiple Data sources\n",
    "- Once the timeseries is indexed correctly (ascending or descending) accessing rows and columns is fairly flexible\n",
    "- Special care **MUST** be taken when loading in data from Excel Spreadsheets and CSV files\n",
    "- Also be careful with date formats\n",
    "- e.g. 2010-03-01 and 2010-01-03 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_GOOGL = pd.read_csv(filepath_or_buffer='../Data/GOOGL.csv', index_col='Date', parse_dates=True)\n",
    "\n",
    "df_GOOGL.tail()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Date Ranges\n",
    "\n",
    "Note that sometimes when slicing by date range, you can be caught out by the order of the dates in your index.\n",
    "\n",
    "i.e. is the first row the earliest date OR the latest date?\n",
    "\n",
    "It's good practice when dealing with dates as your index, to explicitly sort the index before filtering by a slice of dates. This avoids any surprises.\n",
    "\n",
    "The slice you filter by must match the sorted order of the index:\n",
    "- if the index is sorted ascending (earliest date first) then the slice will be: **df['early_date' : 'late_date']**\n",
    "- if the index is sorted descending (earliest date last) then the slice will be: **df['late_date' : 'early_date']**\n",
    "- If your index and slice order aren't the same then an empty DataFrame will be returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# slice between specific dates\n",
    "df_GOOGL['2010-12-02':'2010-12-25']\n",
    "\n",
    "# In steps of 30 calendar days\n",
    "df_GOOGL['2010-12':'2012-1':30]\n",
    "\n",
    "# between months in steps of 45 days\n",
    "df_GOOGL['2010-Nov':'2011-MAY':45]\n",
    "\n",
    "# use variables\n",
    "start = datetime(2015, 11, 2)\n",
    "stop = datetime(2015,12,23)\n",
    "\n",
    "df_GOOGL[start:stop]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Date Ranges and Frequencies\n",
    "\n",
    "- Extremely useful in the field of finance\n",
    "- Convenient syntax\n",
    "- version 1 - start, stop, frequency\n",
    "- version 2 - start, frequency, periods\n",
    "\n",
    "- full list of date frequencies here - http://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calendar Quarters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.date_range(start='2010-01-01', end='2015-12-31', freq='Q')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calendar Quarters beginning in January\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.date_range(start='2010-01-01', end='2015-12-31', freq='Q-JAN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3rd Friday of Every Month\n",
    "\n",
    "Note that there are special 'business rules' for some dates\n",
    "\n",
    "The pandas lbrary designers put anchors etc. into some of their frequency accessors:\n",
    "\n",
    "http://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#anchored-offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.date_range(start='2010-01-01', end='2015-12-31', freq='WOM-3FRI')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date Range in 4 Hour intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are also some convenient syntax\n",
    "pd.date_range(start='2010-01-01', end='2010-03-01', freq='4H')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date Range in  1 hour and 13 min intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.date_range(start='2010-01-01', periods=10, freq='1h13min')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use a Start, Frequency and periods for other variations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.date_range(start='2010-01-01', freq='WOM-3FRI', periods=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use a date range to lookup/retrieve data from a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days_of_month = pd.date_range(start='2010', end='2011', freq='BM')\n",
    "\n",
    "df_GOOGL.reindex(labels=days_of_month)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shifting\n",
    "\n",
    "Sliding data along a timeseries index\n",
    "\n",
    "- Shift forward - the most recent are lost - Nan\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_GOOGL.shift(1).head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_GOOGL.shift(1).tail()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resampling\n",
    "\n",
    "Resampling is a conversion between frequencies\n",
    "\n",
    "- **Downsampling** - the easiest - going from a finer grained frequency to a lower grained frequency. e.g. Days to Months, Months to Years\n",
    "- **Upsampling** - slightly more involved - the reverse, e.g. months to days, days to minutes\n",
    "\n",
    "Upsampling will require some interpolation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UpSample - Days in to Years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_GOOGL.resample(rule='Y').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Upsample - all days into year 2010 into months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_MON = df_GOOGL.loc['2010'].resample(rule = 'M').mean()\n",
    "df_MON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downsample - Months into Weeks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_MON.resample(rule='W').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Fill to replace NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_MON.resample(rule='W').ffill()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backward fill to replace NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_MON.resample(rule='W').bfill()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpolate to replace NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolate\n",
    "# default is linear\n",
    "df_MON.resample(rule='D').interpolate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot some different interpolations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create am Empty DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp = pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a colum called `Linear`\n",
    "\n",
    "For linear interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp['Linear'] = df_MON['Open'].resample(rule='D').interpolate(method='linear')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a colum called `Quadratic`\n",
    "\n",
    "For quadratic interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp['Quadratic']  = df_MON['Open'].resample(rule='D').interpolate(method='quadratic')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a colum called `Cubic`\n",
    "\n",
    "For cubic interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp['Cubic'] = df_MON['Open'].resample(rule='D').interpolate(method='cubic')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the Interpolations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moving Windows\n",
    "\n",
    "- `rolling()` - create a window and slide along, returning a Series as you go\n",
    "- `expanding()` - gradually increase the size of your window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Moviong Averages\n",
    "\n",
    "`Adj Close`\n",
    "\n",
    "42 day moving average of `Adj Close`\n",
    "\n",
    "252 day moving average of `Adj Close`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_GOOGL['Adj Close'].plot()\n",
    "df_GOOGL['Adj Close'].rolling(window=42).mean().plot()\n",
    "df_GOOGL['Adj Close'].rolling(window=252).mean().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Expanding WIndows\n",
    "\n",
    "`Adj Close`\n",
    "\n",
    "Expanding `Adj Close`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_GOOGL['Adj Close'].plot()\n",
    "df_GOOGL['Adj Close'].expanding().mean().plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregating Data\n",
    "\n",
    "- Quite often you will want to resample and apply a function to the aggregate\n",
    "- You have already done this, e.g. **df.resample(rule='BQ').mean()**\n",
    "- A more convenient way is to use the `agg()` method and supply it with the name of the function you want to apply to your aggregate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate mean aggregated by year - Option 1 use `mean`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_GOOGL.resample(rule='Y').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate mean aggregated by year - Option 2 use `agg`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_GOOGL.resample(rule='Y').agg('mean') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use a variable to store the name of the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func = 'mean'\n",
    "df_GOOGL.resample(rule='Y').agg(func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate by `mean`, `max` and `min`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "funcs = ['mean', 'max', 'min']\n",
    "df_GOOGL.resample(rule='Y').agg(funcs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More sophisticated aggregations\n",
    "\n",
    "Functions\n",
    "- 'mean', 'max', 'min'\n",
    "\n",
    "\n",
    "Columns\n",
    "- 'High', 'Low'\n",
    "\n",
    "\n",
    "Date Range\n",
    "- 2016 to 2017\n",
    "\n",
    "\n",
    "Period\n",
    "- Business Quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "funcs = ['mean', 'max', 'min']\n",
    "cols = ['High', 'Low']\n",
    "from_date = '2016'\n",
    "to_date = '2017'\n",
    "freq = 'BQ'\n",
    "\n",
    "# And now only for 2016 to 2017 but for Business Quarter\n",
    "df_GOOGL[from_date:to_date][cols].resample(rule=freq).agg(funcs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Same as above but transpose results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_GOOGL[from_date:to_date][cols].resample(rule=freq).agg(funcs).transpose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
